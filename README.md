# ğŸš€ Modern Data Platform - Complete Stack

<div align="center">
  
  <h2>âš¡ Production-Ready Data Engineering Infrastructure</h2>
  <p><strong>Real-Time Streaming â€¢ Distributed Processing â€¢ Advanced Analytics</strong></p>
  
  <br>
  
  ### ğŸ› ï¸ **Technology Stack**
  
  <table>
    <tr>
      <td align="center" width="140">
        <img src="https://raw.githubusercontent.com/docker/compose/main/logo.png" width="48" height="48" alt="Docker"/>
        <br><strong>Docker</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/apache_kafka/apache_kafka-icon.svg" width="48" height="48" alt="Kafka"/>
        <br><strong>Kafka</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/apache_spark/apache_spark-icon.svg" width="48" height="48" alt="Spark"/>
        <br><strong>Spark</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/apache_airflow/apache_airflow-icon.svg" width="48" height="48" alt="Airflow"/>
        <br><strong>Airflow</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/postgresql/postgresql-icon.svg" width="48" height="48" alt="PostgreSQL"/>
        <br><strong>PostgreSQL</strong>
      </td>
    </tr>
    <tr>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/mysql/mysql-icon.svg" width="48" height="48" alt="MySQL"/>
        <br><strong>MySQL</strong>
      </td>
      <td align="center" width="140">
        <img src="https://clickhouse.com/images/ch_gh_logo_rounded.png" width="48" height="48" alt="ClickHouse"/>
        <br><strong>ClickHouse</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/jupyter/jupyter-icon.svg" width="48" height="48" alt="Jupyter"/>
        <br><strong>Jupyter</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/grafana/grafana-icon.svg" width="48" height="48" alt="Grafana"/>
        <br><strong>Grafana</strong>
      </td>
      <td align="center" width="140">
        <img src="https://min.io/resources/img/logo.svg" width="48" height="48" alt="MinIO"/>
        <br><strong>MinIO</strong>
      </td>
    </tr>
    <tr>
      <td align="center" width="140">
        <img src="https://www.vectorlogo.zone/logos/redis/redis-icon.svg" width="48" height="48" alt="Redis"/>
        <br><strong>Redis</strong>
      </td>
      <td align="center" width="140">
        <img src="https://cdn.worldvectorlogo.com/logos/kafka-connect.svg" width="48" height="48" alt="Kafka Connect"/>
        <br><strong>Kafka Connect</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.confluent.io/wp-content/themes/confluent/assets/images/confluent-logo-300-2.png" width="48" height="48" alt="Schema Registry"/>
        <br><strong>Schema Registry</strong>
      </td>
      <td align="center" width="140">
        <img src="https://delta.io/static/delta-lake-logo-0ab0f09be5fbc1840a3a7491953fe8ea.svg" width="48" height="48" alt="Delta Lake"/>
        <br><strong>Delta Lake</strong>
      </td>
      <td align="center" width="140">
        <img src="https://www.apache.org/logos/res/iceberg/iceberg.png" width="48" height="48" alt="Iceberg"/>
        <br><strong>Apache Iceberg</strong>
      </td>
    </tr>
  </table>

  <br>
  
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white"/>
  <img src="https://img.shields.io/badge/Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white"/>
  <img src="https://img.shields.io/badge/Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white"/>
  <img src="https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white"/>
  <br>
  <img src="https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white"/>
  <img src="https://img.shields.io/badge/MySQL-005C84?style=for-the-badge&logo=mysql&logoColor=white"/>
  <img src="https://img.shields.io/badge/ClickHouse-FFCC01?style=for-the-badge&logo=clickhouse&logoColor=black"/>
  <img src="https://img.shields.io/badge/MinIO-C72E49?style=for-the-badge&logo=minio&logoColor=white"/>
</div>

---

## ğŸ¯ Platform Overview

Welcome to a **comprehensive, production-grade data platform** built entirely with Docker Compose! This infrastructure enables end-to-end data engineering workflows from ingestion to visualization, supporting real-time streaming, distributed processing, and advanced analytics.

### ğŸŒŸ **Key Capabilities**
- ğŸ”¥ **Real-time data streaming** with Apache Kafka
- âš¡ **Distributed processing** using Apache Spark
- ğŸ”„ **Workflow orchestration** via Apache Airflow
- ğŸ“Š **Multiple database engines** (OLTP & OLAP)
- ğŸ—„ï¸ **Object storage** with MinIO (S3-compatible)
- ğŸ“ˆ **Data visualization** with Grafana
- ğŸ”§ **Schema management** with Confluent Schema Registry
- ğŸ“ **Interactive development** through Jupyter notebooks

---

## ğŸ—ï¸ Architecture Stack

<div align="center">

### **Complete Technology Ecosystem**

| Layer | Technologies | Purpose |
|:-----:|:------------|:--------|
| **ğŸ—„ï¸ Storage** | PostgreSQL, MySQL, ClickHouse, MinIO | Multi-model data storage |
| **ğŸ”„ Streaming** | Kafka, Schema Registry, Kafka Connect | Real-time data pipelines |
| **âš¡ Processing** | Apache Spark (Master/Worker) | Distributed computation |
| **ğŸ”§ Orchestration** | Apache Airflow | Workflow automation |
| **ğŸ“Š Visualization** | Grafana, Kafka UI, Jupyter | Monitoring & analysis |
| **ğŸŒ Networking** | Docker Bridge Network | Service communication |

</div>

---

## ğŸ“¦ Services Overview

<div align="center">

### **12 Integrated Services**

| Service | Port(s) | Category | Status |
|:--------|:--------|:---------|:------:|
| **PostgreSQL** | 5432 | Database | âœ… |
| **MySQL** | 3305 | Database | âœ… |
| **ClickHouse** | 8123, 9000 | Analytics DB | âœ… |
| **MinIO** | 9001, 9002 | Object Storage | âœ… |
| **Kafka Broker** | 9092 | Streaming | âœ… |
| **Schema Registry** | 8081 | Schema Mgmt | âœ… |
| **Kafka Connect** | 8083 | Integration | âœ… |
| **Kafka UI** | 8090 | Monitoring | âœ… |
| **Spark Master** | 7077, 8180 | Processing | âœ… |
| **Spark Worker** | 8181 | Processing | âœ… |
| **Jupyter** | 8888 | Development | âœ… |
| **Airflow** | 8084 | Orchestration | âœ… |
| **Grafana** | 3001 | Visualization | âœ… |

</div>

---

## ğŸš€ Quick Start Guide

### **Prerequisites**
- Docker Engine 20.10+
- Docker Compose 2.0+
- 16GB RAM minimum (32GB recommended)
- 50GB free disk space

### **ğŸ”¥ Launch the Platform**

```bash
# Navigate to project directory
cd your-project-directory

# Start all services
docker-compose up -d

# Check service health
docker-compose ps

# View logs for specific service
docker-compose logs -f <service-name>

# Stop all services
docker-compose down

# Stop and remove volumes (âš ï¸ deletes all data)
docker-compose down -v
```

---

## ğŸ¯ Access Dashboard

<div align="center">

### **Service Access URLs**

| Service | URL | Default Credentials |
|:--------|:----|:-------------------|
| ğŸ¨ **Spark Master UI** | http://localhost:8180 | No authentication |
| âš¡ **Spark Worker UI** | http://localhost:8181 | No authentication |
| ğŸ““ **Jupyter Notebook** | http://localhost:8888 | No password required |
| ğŸ”§ **Airflow Webserver** | http://localhost:8084 | Create on first run |
| ğŸ“Š **Kafka UI** | http://localhost:8090 | No authentication |
| ğŸ”Œ **Kafka Connect** | http://localhost:8083 | REST API |
| ğŸ—„ï¸ **MinIO Console** | http://localhost:9001 | minio / minio123 |
| ğŸ“ˆ **Grafana** | http://localhost:3001 | admin / admin |
| ğŸ” **ClickHouse HTTP** | http://localhost:8123 | default / 123 |

</div>

---

## ğŸ’¡ Use Cases & Applications

<div align="center">

### **1ï¸âƒ£ Real-Time Analytics Pipeline**
`Source Data â†’ Kafka â†’ Spark Streaming â†’ ClickHouse â†’ Grafana`

### **2ï¸âƒ£ Batch ETL Workflow**
`Data Lakes â†’ Airflow â†’ Spark Jobs â†’ Delta Lake â†’ Analytics`

### **3ï¸âƒ£ Change Data Capture (CDC)**
`MySQL/PostgreSQL â†’ Kafka Connect â†’ Event Stream â†’ Consumers`

### **4ï¸âƒ£ Machine Learning Pipeline**
`Raw Data â†’ Spark ML â†’ Model Training â†’ Jupyter Analysis`

### **5ï¸âƒ£ Data Lake Architecture**
`Multiple Sources â†’ MinIO Storage â†’ Iceberg/Delta Tables â†’ Query Layer`

</div>

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ Data Platform
â”œâ”€â”€ ğŸ—„ï¸ databases/
â”‚   â”œâ”€â”€ postgres/
â”‚   â”œâ”€â”€ clickhouse/
â”‚   â””â”€â”€ mongodb/ (optional)
â”‚
â”œâ”€â”€ ğŸ”„ kafka/
â”‚   â”œâ”€â”€ jmx/
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ jar/
â”‚
â”œâ”€â”€ âš¡ spark/
â”‚   â”œâ”€â”€ jar/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Dockerfiles/
â”‚
â”œâ”€â”€ ğŸ”§ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ config/
â”‚
â”œâ”€â”€ ğŸ—„ï¸ minio/data/
â”‚
â””â”€â”€ ğŸ³ docker-compose.yml
```

---

## ğŸ› ï¸ Technology Stack Details

### **ğŸ—„ï¸ Databases**
- **PostgreSQL 14** - ACID-compliant relational database with logical replication
- **MySQL 8.0** - Popular open-source RDBMS for application data
- **ClickHouse** - High-performance columnar database for analytics

### **ğŸ”„ Streaming Layer**
- **Apache Kafka 7.6** - Distributed event streaming platform (KRaft mode)
- **Schema Registry** - Centralized schema management for Kafka
- **Kafka Connect** - Integration framework with JDBC connectors

### **âš¡ Processing Engine**
- **Apache Spark 3.4.2** - Unified analytics engine for big data
- **Jupyter Notebook** - Interactive development environment
- **Pre-loaded Libraries**: Kafka, Delta Lake, Iceberg, Database connectors

### **ğŸ”§ Orchestration**
- **Apache Airflow** - Platform for workflow automation
- **Celery Executor** - Distributed task execution
- **Redis** - Message broker for Celery workers

### **ğŸ“Š Storage & Visualization**
- **MinIO** - S3-compatible object storage for data lakes
- **Grafana** - Multi-platform analytics and visualization

---

## ğŸ“ Getting Started Guides

### **For Data Engineers**
1. Set up Kafka topics and connectors
2. Design Spark streaming applications
3. Build Airflow DAGs for orchestration
4. Configure data lake on MinIO

### **For Data Analysts**
1. Access Jupyter for exploratory analysis
2. Query ClickHouse for fast analytics
3. Create Grafana dashboards
4. Monitor Kafka streams via UI

### **For Data Scientists**
1. Load data into Spark DataFrames
2. Train models using Spark MLlib
3. Store results in Delta Lake
4. Version datasets with Iceberg

---

## ğŸ”§ Configuration & Customization

### **Scaling Resources**
Modify worker resources in `docker-compose.yml`:
- Spark worker cores and memory
- Airflow worker count
- Database connection pools

### **Adding Services**
Uncomment optional services:
- MongoDB for NoSQL storage
- Apache Flink for stream processing
- Trino for federated queries
- DBT for transformations
- Apache NiFi for data flows
- Superset/Metabase for BI

### **Network Configuration**
All services communicate via `data-net` bridge network for isolation and performance.

---

## ğŸ” Security Best Practices

### **Production Checklist**
- âœ… Change all default passwords
- âœ… Enable SSL/TLS for services
- âœ… Configure authentication on Kafka
- âœ… Set up role-based access control
- âœ… Enable encryption at rest
- âœ… Implement network policies
- âœ… Regular security updates
- âœ… Audit logging enabled

---

## ğŸ› Troubleshooting

### **Common Issues**

**Services won't start?**
- Check Docker resources (CPU, Memory)
- Verify port availability
- Review service logs
- Ensure sufficient disk space

**Performance issues?**
- Increase Docker memory allocation
- Scale Spark worker resources
- Optimize Kafka configurations
- Monitor resource usage

**Connection problems?**
- Verify network connectivity
- Check service health status
- Review firewall settings
- Validate credentials

**Data persistence?**
- Ensure volume mounts are correct
- Check directory permissions
- Verify volume existence
- Backup important data

---

## ğŸ“Š Monitoring & Observability

### **Built-in Monitoring**
- **JMX Metrics** - Kafka, Schema Registry, Kafka Connect
- **Spark UI** - Job tracking and performance metrics
- **Airflow UI** - DAG execution and task monitoring
- **Grafana** - Custom dashboards and alerting
- **Kafka UI** - Topic and consumer group insights

### **Health Checks**
Monitor service health with `docker-compose ps` and individual service logs.

---

## ğŸš€ Advanced Features

### **Supported Integrations**
- âœ… Apache Iceberg & Delta Lake for data lakehouse
- âœ… AWS S3 compatibility via MinIO
- âœ… Snowflake connector for cloud DW
- âœ… MongoDB for document storage
- âœ… Multiple JDBC sources
- âœ… Custom Kafka connectors
- âœ… HTTP source connectors

### **Data Formats**
- Parquet, ORC, Avro
- JSON, CSV, XML
- Delta, Iceberg tables
- Binary formats

---

## ğŸ“š Learning Resources

### **Official Documentation**
- [Apache Kafka Docs](https://kafka.apache.org/documentation/)
- [Apache Spark Guide](https://spark.apache.org/docs/latest/)
- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [ClickHouse Documentation](https://clickhouse.com/docs/)
- [MinIO Documentation](https://min.io/docs/)
- [Delta Lake Guide](https://delta.io/)

### **Community Resources**
- Docker Compose best practices
- Kafka streaming patterns
- Spark optimization guides
- Airflow DAG design patterns

---

## ğŸ¯ Next Steps

1. **ğŸš€ Deploy** - Start the platform with `docker-compose up -d`
2. **ğŸ” Explore** - Access each service via web interfaces
3. **ğŸ’¡ Experiment** - Create topics, write streams, build pipelines
4. **ğŸ“Š Visualize** - Set up Grafana dashboards
5. **ğŸ”§ Automate** - Design Airflow workflows
6. **âš¡ Scale** - Add workers and optimize performance

---

## ğŸ¤ Contributing & Support

### **Ideal For**
- ğŸ“ Learning modern data engineering
- ğŸ”¬ Prototyping data solutions
- ğŸ—ï¸ Building POCs
- ğŸ“Š Testing architectures
- ğŸ’¼ Training environments

### **Community**
- Share your use cases
- Report issues and improvements
- Contribute enhancements
- Document best practices

---

<div align="center">

### âš¡ **"Build. Learn. Scale. Repeat."**

**Everything you need for modern data engineering in one platform!** ğŸš€

---

*Empowering data engineers to build real-world solutions* â¤ï¸

**â­ Star this repository if you find it useful! â­**

---

[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker)](https://www.docker.com/)
[![Kafka](https://img.shields.io/badge/Kafka-Streaming-231F20?style=flat-square&logo=apache-kafka)](https://kafka.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-Processing-E25A1C?style=flat-square&logo=apache-spark)](https://spark.apache.org/)
[![Airflow](https://img.shields.io/badge/Airflow-Orchestration-017CEE?style=flat-square&logo=apache-airflow)](https://airflow.apache.org/)

**Version 1.0** | Production-Ready | Docker Compose

</div>